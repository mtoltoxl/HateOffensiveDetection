# HateOffensiveDetection

## baseline.py
  The baseline is the pretrained BERT model from the huggingface with the linear classifier on top where the parameters of the BERT model are frozen and those of linear classifier are updated.
The file 'baseline.py' should be activated to reproduce the result that we've come across.
  -> python baseline.py

## hatexplain.py
  The first experimental design is the pretrained BERT model with the linear classifier on top where the parameters of both BERT model and linear classifier are updated.
The file 'hatexplain.py' should be activated to reproduce the result that we've come across.
  -> python hatexplain.py
  
## tweet_classify.py
  The second experimental design is the same with the first design but with the data augmentation. We have augmented the tweets with 'hate' label with RoBERTa ('roberta-base') accomodating random replacement technique. Based on the rationale provided in the dataset, we mask tokens that correspond to '0' and randomly replace the <Mask> token with the word generated by the RoBERTa model. We've achieved to augment 2151 more 'hate' tweets.
The file 'tweet_classify.py' should be executed to reproduce the result that we've come across.
  -> python tweet_classify.py
  
### Auxiliaries
  We have implemented a number of auxiliary experiments to analyse the capability / performance of our model under different settings.

  #### hn_o_classify.py
   In this auxiliary experiment, we checked whether our model can binary classify normal and offensive + hate tweets. This is the easy case where the hate and offensive tweets are considered the same label. This experiment has been conducted to check whether distinguishing hate and offensive tweets is an easy or difficult task.
  
  #### h_o_classify.py
   In this auxiliary experiment, we checked whether our model can binary classify offensive and hate tweets. Since it is quite difficult to distinguish these two without domain knowledge on the characteristics of each tweet.
